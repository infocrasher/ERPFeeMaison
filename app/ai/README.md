# Module AI - Intelligence Artificielle pour l'ERP F√©e Maison

## üìã Vue d'ensemble

Le module AI int√®gre **Prophet** (pr√©dictions temporelles) et **LLM** (Groq/GPT-4o mini) pour fournir une analyse intelligente et pr√©dictive des rapports de l'ERP.

## üß© Architecture

```
app/ai/
‚îú‚îÄ‚îÄ __init__.py                    # Blueprint Flask
‚îú‚îÄ‚îÄ ai_manager.py                  # Orchestrateur principal
‚îú‚îÄ‚îÄ model_trainer.py               # Entra√Ænement Prophet (CLI)
‚îú‚îÄ‚îÄ context_builder.py             # Construction de contexte
‚îú‚îÄ‚îÄ routes.py                      # Endpoints Flask
‚îú‚îÄ‚îÄ prompt_templates.yaml          # Templates de prompts LLM
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ prophet_predictor.py       # Service Prophet
‚îÇ   ‚îî‚îÄ‚îÄ llm_analyzer.py            # Service LLM (Groq/OpenAI)
‚îú‚îÄ‚îÄ models/                        # Mod√®les Prophet (.pkl)
‚îî‚îÄ‚îÄ cache/                         # Cache temporaire
```

## üöÄ Installation

### 1. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 2. Configurer les cl√©s API (optionnel)

Ajouter dans `.env` :

```bash
# Pour Groq (recommand√©, gratuit)
GROQ_API_KEY=your_groq_api_key_here

# OU pour OpenAI
OPENAI_API_KEY=your_openai_api_key_here
```

> **Note**: Si aucune cl√© API n'est configur√©e, le module fonctionne en mode **fallback local** (analyse simplifi√©e sans LLM externe).

### 3. Entra√Æner les mod√®les Prophet

```bash
# Entra√Æner tous les mod√®les
python app/ai/model_trainer.py

# Entra√Æner un rapport sp√©cifique
python app/ai/model_trainer.py --report daily_sales --days 90

# G√©n√©rer une pr√©diction
python app/ai/model_trainer.py --report daily_sales --predict --forecast-days 7
```

## üì° API Endpoints

### Status du module

```bash
GET /ai/status
```

R√©ponse :
```json
{
  "status": "ok",
  "prophet": {
    "available": true,
    "models_count": 11
  },
  "llm": {
    "provider": "groq",
    "model": "llama-3.1-70b-versatile",
    "available": true
  }
}
```

### Entra√Ænement des mod√®les

```bash
POST /ai/train
Content-Type: application/json

{
  "report_name": "daily_sales",  # optionnel
  "days_history": 90             # optionnel
}
```

### Pr√©dictions Prophet

```bash
GET /ai/predict?report=daily_sales&days=7&date=2025-01-15
```

R√©ponse :
```json
{
  "success": true,
  "forecast": [
    {
      "ds": "2025-01-16",
      "yhat": 45000.5,
      "yhat_lower": 40000.0,
      "yhat_upper": 50000.0
    },
    ...
  ],
  "metrics": {
    "mae": 1250.5,
    "mape": 8.2,
    "confidence": "√©lev√©e"
  }
}
```

### Analyse LLM

```bash
GET /ai/analyze?report=daily_sales&date=2025-01-15&prompt_type=daily_analysis&include_forecast=true
```

R√©ponse :
```json
{
  "success": true,
  "analysis": "üìä ANALYSE DU RAPPORT...",
  "provider": "groq",
  "model": "llama-3.1-70b-versatile",
  "context_summary": {
    "growth_rate": 5.2,
    "trend": "up",
    "variance": 125.5
  }
}
```

### D√©tection d'anomalies

```bash
GET /ai/anomalies?report=daily_sales&date=2025-01-15
```

### R√©sum√© global

```bash
GET /ai/summary?type=daily&date=2025-01-15
```

Types disponibles : `daily`, `weekly`, `monthly`

## üíª Utilisation en Python

### Pr√©dictions Prophet

```python
from app.ai.ai_manager import AIManager

ai = AIManager()

# G√©n√©rer des pr√©dictions √† 7 jours
forecast = ai.generate_forecasts('daily_sales', days=7)

if forecast['success']:
    for pred in forecast['forecast']:
        print(f"{pred['ds']}: {pred['yhat']:.2f}")
```

### Analyse LLM

```python
from app.ai.ai_manager import AIManager
from datetime import date

ai = AIManager()

# Analyser un rapport
analysis = ai.analyze_reports(
    report_name='daily_sales',
    report_date=date(2025, 1, 15),
    prompt_type='daily_analysis',
    include_forecast=True
)

print(analysis['analysis'])
```

### D√©tection d'anomalies

```python
ai = AIManager()

anomalies = ai.detect_anomalies('daily_sales')

if anomalies['success']:
    print(anomalies['analysis'])
    print(f"Z-score: {anomalies['statistics']['z_score']}")
```

## üß™ Types de prompts disponibles

D√©finis dans `prompt_templates.yaml` :

- **`daily_analysis`** : Analyse quotidienne avec KPI
- **`weekly_summary`** : R√©sum√© hebdomadaire
- **`anomaly_detection`** : D√©tection d'anomalies
- **`recommendations`** : Recommandations strat√©giques
- **`forecast_analysis`** : Interpr√©tation des pr√©dictions Prophet
- **`period_comparison`** : Comparaison inter-p√©riodes
- **`cashflow_analysis`** : Analyse de tr√©sorerie
- **`product_profitability`** : Analyse de rentabilit√© produit

## üìä Rapports support√©s

Le module AI supporte les 12 rapports de l'ERP :

### Quotidiens
- `daily_sales` : Ventes quotidiennes
- `daily_prime_cost` : Prime cost
- `daily_production` : Production
- `daily_stock_alerts` : Alertes stock
- `daily_waste_loss` : Pertes & gaspillage

### Hebdomadaires
- `weekly_product_performance` : Performance produits
- `weekly_stock_rotation` : Rotation des stocks
- `weekly_labor_cost` : Co√ªts main d'≈ìuvre
- `weekly_cash_flow` : Pr√©vision tr√©sorerie

### Mensuels
- `monthly_gross_margin` : Marge brute
- `monthly_profit_loss` : Compte de r√©sultat

## üîß Configuration avanc√©e

### Changer de provider LLM

```python
# Utiliser OpenAI au lieu de Groq
ai = AIManager(llm_provider='openai')

# Utiliser un mod√®le sp√©cifique
ai = AIManager(llm_provider='groq', llm_model='mixtral-8x7b-32768')

# Forcer le mode fallback local
ai = AIManager(llm_provider='fallback')
```

### Personnaliser les prompts

√âditer `app/ai/prompt_templates.yaml` :

```yaml
custom_analysis:
  system: >
    Tu es un expert en...
  user: >
    Voici les donn√©es : {{ data }}
    Analyse-les selon...
```

Utiliser :
```python
analysis = ai.analyze_reports(
    report_name='daily_sales',
    prompt_type='custom_analysis'
)
```

## üìà Prophet - Configuration

### Param√®tres d'entra√Ænement

```python
from app.ai.model_trainer import train_model

result = train_model(
    report_name='daily_sales',
    days_history=90,  # Jours d'historique
    save_model=True   # Sauvegarder le mod√®le
)
```

### M√©triques de qualit√©

- **MAE** (Mean Absolute Error) : Erreur moyenne absolue
- **MAPE** (Mean Absolute Percentage Error) : Erreur en %
- **RMSE** (Root Mean Square Error) : Erreur quadratique moyenne
- **Confidence** : Niveau de confiance (tr√®s_√©lev√©e, √©lev√©e, moyenne, faible)

| MAPE | Confidence |
|------|------------|
| < 10% | Tr√®s √©lev√©e |
| 10-20% | √âlev√©e |
| 20-30% | Moyenne |
| > 30% | Faible |

## üõ†Ô∏è D√©pannage

### Prophet non disponible

```
‚ö†Ô∏è  Prophet n'est pas install√©. Les pr√©dictions seront d√©sactiv√©es.
```

**Solution** :
```bash
pip install prophet==1.1.5
```

### LLM en mode fallback

```
‚ö†Ô∏è  Aucune cl√© API d√©tect√©e. Mode fallback activ√©.
```

**Solution** : Ajouter `GROQ_API_KEY` ou `OPENAI_API_KEY` dans `.env`

### Donn√©es historiques insuffisantes

```
‚ùå Donn√©es insuffisantes pour daily_sales (5 lignes)
```

**Solution** : Le module Prophet n√©cessite au moins 10-15 jours de donn√©es historiques.

## üìù Logs

Les logs du module AI sont disponibles dans :
- Console (niveau INFO)
- `logs/fee_maison.log` (niveau DEBUG)

## üîí S√©curit√©

- Les cl√©s API sont stock√©es dans `.env` (non versionn√©)
- Les mod√®les Prophet sont sauvegard√©s localement (pas de transmission externe)
- Les analyses LLM ne stockent pas les donn√©es sur les serveurs externes apr√®s g√©n√©ration

## üöÄ Roadmap

- [ ] Int√©gration avec les dashboards Flask
- [ ] Alertes automatiques par email
- [ ] Export PDF des analyses AI
- [ ] Analyse multi-rapports avanc√©e
- [ ] Fine-tuning des mod√®les Prophet par saison
- [ ] Support de mod√®les LLM locaux (Ollama)

## üìö Ressources

- [Documentation Prophet](https://facebook.github.io/prophet/)
- [API Groq](https://console.groq.com/)
- [API OpenAI](https://platform.openai.com/)

## ‚úÖ Checklist de d√©ploiement

- [ ] Installer les d√©pendances (`pip install -r requirements.txt`)
- [ ] Configurer les cl√©s API dans `.env`
- [ ] Entra√Æner les mod√®les Prophet (`python app/ai/model_trainer.py`)
- [ ] Tester l'API (`curl http://localhost:5000/ai/status`)
- [ ] V√©rifier les logs
- [ ] Ajouter le blueprint AI √† l'application Flask

## ü§ù Contribution

Le module AI est con√ßu pour √™tre extensible. Pour ajouter un nouveau type de rapport :

1. Ajouter le service dans `app/reports/services.py`
2. Ajouter le mapping dans `ContextBuilder.REPORT_SERVICES`
3. Ajouter un prompt template dans `prompt_templates.yaml`
4. Entra√Æner le mod√®le Prophet

---

**Version** : 1.0.0  
**Auteur** : ERP F√©e Maison  
**Date** : Novembre 2025

